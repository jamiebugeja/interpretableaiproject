{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416211f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "#Test Push\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "train_adult = pd.read_csv(\"DataSets/census/adult.data\", header=None, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True)\n",
    "test_adult = pd.read_csv(\"DataSets/census/adult.test\", header=0, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True, comment='|')\n",
    "test_adult['income'] = test_adult['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "data_adult = pd.concat([train_adult, test_adult], ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e81b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16896f5e",
   "metadata": {},
   "source": [
    "# Part 1: Feature-Level Interpretability (30 marks)  \n",
    "You will use the California Housing and the Adult Census Income datasets in this part. You \n",
    "should train one feed-forward neural network for each dataset and apply the following \n",
    "interpretability techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ef54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4316 - val_accuracy: 0.8533 - val_loss: 0.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3173 - val_accuracy: 0.8547 - val_loss: 0.3113\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3182 - val_accuracy: 0.8566 - val_loss: 0.3093\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.3056 - val_accuracy: 0.8585 - val_loss: 0.3074\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3080 - val_accuracy: 0.8572 - val_loss: 0.3072\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.3062 - val_accuracy: 0.8573 - val_loss: 0.3074\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3038 - val_accuracy: 0.8590 - val_loss: 0.3057\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3069 - val_accuracy: 0.8625 - val_loss: 0.3057\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3035 - val_accuracy: 0.8599 - val_loss: 0.3064\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3025 - val_accuracy: 0.8606 - val_loss: 0.3065\n",
      "Validation Accuracy: 0.8606\n"
     ]
    }
   ],
   "source": [
    "# Adult Census Income Dataset pre-processing and neural network model\n",
    "\n",
    "X_adult = data_adult.drop(\"income\", axis=1)\n",
    "y_adult = (data_adult[\"income\"] == \">50K\").astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X_adult.select_dtypes(include=['object']).columns\n",
    "num_cols = X_adult.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Encode categorical & scale numeric\n",
    "ct = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('scale', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "X_processed_adult = ct.fit_transform(X_adult)\n",
    "X_train_adult, X_val_adult, y_train_adult, y_val_adult = train_test_split(X_processed_adult, y_adult, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim = X_train_adult.shape[1]\n",
    "\n",
    "# The feed-forward neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=input_dim),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_adult, y_train_adult,\n",
    "    validation_data=(X_val_adult, y_val_adult),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaulate the model\n",
    "loss, acc = model.evaluate(X_val_adult, y_val_adult, verbose=0)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b7af9",
   "metadata": {},
   "source": [
    "## 1. Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots (7 marks) \n",
    "### a. Use PDP to examine the average effect of at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe303b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'estimator' must be a fitted regressor or classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[40], line 35\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- plot PDPs ---\u001b[39;00m\n",
      "\u001b[0;32m     34\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;32m---> 35\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_wrapper\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val_adult\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43medu_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhours_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# tuple -> 2D PDP (interaction)\u001b[39;49;00m\n",
      "\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\n",
      "\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial Dependence: Education × Hours-per-week\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_plot\\partial_dependence.py:707\u001b[0m, in \u001b[0;36mPartialDependenceDisplay.from_estimator\u001b[1;34m(cls, estimator, X, features, sample_weight, categorical_features, feature_names, target, response_method, n_cols, grid_resolution, percentiles, method, n_jobs, verbose, line_kw, ice_lines_kw, pd_line_kw, contour_kw, ax, kind, centered, subsample, random_state)\u001b[0m\n",
      "\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    702\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen a floating-point, subsample=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe (0, 1) range.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    704\u001b[0m         )\n",
      "\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# compute predictions and/or averaged predictions\u001b[39;00m\n",
      "\u001b[1;32m--> 707\u001b[0m pd_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_dependence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_resolution\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# For multioutput regression, we can only check the validity of target\u001b[39;00m\n",
      "\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# now that we have the predictions.\u001b[39;00m\n",
      "\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# Also note: as multiclass-multioutput classifiers are not supported,\u001b[39;00m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# multiclass and multioutput scenario are mutually exclusive. So there is\u001b[39;00m\n",
      "\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# no risk of overwriting target_idx here.\u001b[39;00m\n",
      "\u001b[0;32m    729\u001b[0m pd_result \u001b[38;5;241m=\u001b[39m pd_results[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# checking the first result is enough\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[0;32m     76\u001b[0m )\n",
      "\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m    214\u001b[0m         )\n",
      "\u001b[0;32m    215\u001b[0m     ):\n",
      "\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[0;32m    226\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_partial_dependence.py:537\u001b[0m, in \u001b[0;36mpartial_dependence\u001b[1;34m(estimator, X, features, sample_weight, categorical_features, feature_names, response_method, percentiles, grid_resolution, method, kind)\u001b[0m\n",
      "\u001b[0;32m    534\u001b[0m check_is_fitted(estimator)\n",
      "\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_classifier(estimator) \u001b[38;5;129;01mor\u001b[39;00m is_regressor(estimator)):\n",
      "\u001b[1;32m--> 537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a fitted regressor or classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(estimator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulticlass-multioutput estimators are not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: 'estimator' must be a fitted regressor or classifier."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# --- Keras → sklearn wrapper ---\n",
    "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    _estimator_type = \"regressor\"  # tell sklearn what this is\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        # mark as fitted\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        preds = self.model.predict(X, verbose=0)\n",
    "        return preds.flatten()\n",
    "\n",
    "# wrap model\n",
    "keras_wrapper = KerasRegressorWrapper(model)\n",
    "keras_wrapper.fit()  # mark as fitted\n",
    "\n",
    "# --- PDP setup ---\n",
    "feature_names = list(ct.get_feature_names_out())\n",
    "edu_idx = feature_names.index('scale__education-num')\n",
    "hours_idx = feature_names.index('scale__hours-per-week')\n",
    "\n",
    "# --- plot PDPs ---\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    keras_wrapper,\n",
    "    X_val_adult,\n",
    "    features=[(edu_idx, hours_idx)],  # tuple -> 2D PDP (interaction)\n",
    "    feature_names=feature_names,\n",
    "    grid_resolution=40,\n",
    "    ax=ax\n",
    ")\n",
    "plt.suptitle(\"Partial Dependence: Education × Hours-per-week\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#California Housing Data Set NN + PDP + ICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b39bef",
   "metadata": {},
   "source": [
    "### b. Use ICE plots to explore individual predictions for at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bdca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b6405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fcb7c1",
   "metadata": {},
   "source": [
    "### c. Explain what insights PDP and ICE give about the model’s behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f80c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5948c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e357bb",
   "metadata": {},
   "source": [
    "## 2. Permutation Feature Importance (PFI) (7 marks) \n",
    "### a. Use PFI to identify the most important features in the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ac11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a323045b",
   "metadata": {},
   "source": [
    "### b. Explain what the term “important” means when using the PFI method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054de319",
   "metadata": {},
   "source": [
    "## 3. Accumulated Local Effects (ALE) (9 marks) \n",
    "### a. Implement ALE plots to investigate the local effects of feature changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82633524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0aa2f07",
   "metadata": {},
   "source": [
    "### b. Compare ALE with PDP and discuss any differences in the interpretability of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387257b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1eb403",
   "metadata": {},
   "source": [
    "## 4. Global Surrogates (7 marks) \n",
    "### a. Build an interpretable model to approximate the predictions of the feed-forward neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265eeb5b",
   "metadata": {},
   "source": [
    "### b. Analyse the surrogate model's effectiveness and discuss when such approximations are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
