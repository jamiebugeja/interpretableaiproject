{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
   "id": "416211f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
   "id": "09ff856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "train_adult = pd.read_csv(\"DataSets/census/adult.data\", header=None, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True)\n",
    "test_adult = pd.read_csv(\"DataSets/census/adult.test\", header=0, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True, comment='|')\n",
    "test_adult['income'] = test_adult['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "data_adult = pd.concat([train_adult, test_adult], ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e81b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (20640, 8)\n",
      "Target (y) shape: (20640,)\n",
      "\n",
      "Sample feature names:\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(\"\\nSample feature names:\")\n",
    "print(housing.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16896f5e",
   "metadata": {},
   "source": [
    "# Part 1: Feature-Level Interpretability (30 marks)  \n",
    "You will use the California Housing and the Adult Census Income datasets in this part. You \n",
    "should train one feed-forward neural network for each dataset and apply the following \n",
    "interpretability techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777ef54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7881 - loss: 0.4447 - val_accuracy: 0.8539 - val_loss: 0.3168\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.3196 - val_accuracy: 0.8552 - val_loss: 0.3121\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3113 - val_accuracy: 0.8576 - val_loss: 0.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8589 - loss: 0.3074 - val_accuracy: 0.8575 - val_loss: 0.3077\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.3073 - val_accuracy: 0.8584 - val_loss: 0.3081\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3047 - val_accuracy: 0.8594 - val_loss: 0.3061\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3059 - val_accuracy: 0.8584 - val_loss: 0.3073\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3010 - val_accuracy: 0.8598 - val_loss: 0.3073\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 0.3014 - val_accuracy: 0.8600 - val_loss: 0.3066\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8619 - loss: 0.3019 - val_accuracy: 0.8604 - val_loss: 0.3069\n",
      "Validation Accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom scikeras.wrappers import KerasClassifier\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\\nfrom sklearn.inspection import PartialDependenceDisplay\\nimport matplotlib.pyplot as plt\\n\\n# Wrap the Keras model\\ndef create_model():\\n    model = Sequential([\\n        Dense(128, activation='relu', input_dim=input_dim),\\n        Dropout(0.3),\\n        Dense(64, activation='relu'),\\n        Dropout(0.3),\\n        Dense(1, activation='sigmoid')\\n    ])\\n    model.compile(optimizer=Adam(learning_rate=0.001),\\n                  loss='binary_crossentropy', metrics=['accuracy'])\\n    return model\\n\\n# Wrap in scikit-learn compatible estimator\\nsklearn_model = KerasClassifier(model=create_model, epochs=10, batch_size=256, verbose=0)\\nsklearn_model.fit(X_train_adult, y_train_adult)  # Train the model\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
=======
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.4316 - val_accuracy: 0.8533 - val_loss: 0.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3173 - val_accuracy: 0.8547 - val_loss: 0.3113\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3182 - val_accuracy: 0.8566 - val_loss: 0.3093\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.3056 - val_accuracy: 0.8585 - val_loss: 0.3074\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3080 - val_accuracy: 0.8572 - val_loss: 0.3072\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.3062 - val_accuracy: 0.8573 - val_loss: 0.3074\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3038 - val_accuracy: 0.8590 - val_loss: 0.3057\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3069 - val_accuracy: 0.8625 - val_loss: 0.3057\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3035 - val_accuracy: 0.8599 - val_loss: 0.3064\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3025 - val_accuracy: 0.8606 - val_loss: 0.3065\n",
      "Validation Accuracy: 0.8606\n"
     ]
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
    }
   ],
   "source": [
    "# Adult Census Income Dataset pre-processing and neural network model\n",
    "\n",
    "X_adult = data_adult.drop(\"income\", axis=1)\n",
    "y_adult = (data_adult[\"income\"] == \">50K\").astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X_adult.select_dtypes(include=['object']).columns\n",
    "num_cols = X_adult.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Encode categorical & scale numeric\n",
    "ct = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('scale', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "X_processed_adult = ct.fit_transform(X_adult)\n",
    "X_train_adult, X_val_adult, y_train_adult, y_val_adult = train_test_split(X_processed_adult, y_adult, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim = X_train_adult.shape[1]\n",
    "\n",
    "# The feed-forward neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=input_dim),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_adult, y_train_adult,\n",
    "    validation_data=(X_val_adult, y_val_adult),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaulate the model\n",
    "loss, acc = model.evaluate(X_val_adult, y_val_adult, verbose=0)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841f30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 20640\n",
      "Training data points: 13209\n",
      "Validation data points: 3303\n",
      "Test data points: 4128\n",
      "Data successfully scaled.\n",
      "Original mean (first feature): 3.8689\n",
      "Scaled mean (first feature): -0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\UoM\\Year 3\\ARI3205 Interpretable AI for DL Models\\interpretableaiproject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m833\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m833\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled with 'mean_squared_error' as the loss function.\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.2268 - mean_absolute_error: 0.7803 - val_loss: 0.5965 - val_mean_absolute_error: 0.5545\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4814 - mean_absolute_error: 0.4950 - val_loss: 0.4584 - val_mean_absolute_error: 0.4827\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4050 - mean_absolute_error: 0.4544 - val_loss: 0.4506 - val_mean_absolute_error: 0.4619\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3853 - mean_absolute_error: 0.4406 - val_loss: 0.3976 - val_mean_absolute_error: 0.4502\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3657 - mean_absolute_error: 0.4289 - val_loss: 0.4083 - val_mean_absolute_error: 0.4479\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3509 - mean_absolute_error: 0.4204 - val_loss: 0.3855 - val_mean_absolute_error: 0.4494\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3470 - mean_absolute_error: 0.4140 - val_loss: 0.4603 - val_mean_absolute_error: 0.4341\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3400 - mean_absolute_error: 0.4060 - val_loss: 0.3953 - val_mean_absolute_error: 0.4302\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3224 - mean_absolute_error: 0.3991 - val_loss: 0.3514 - val_mean_absolute_error: 0.4151\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3168 - mean_absolute_error: 0.3953 - val_loss: 0.3622 - val_mean_absolute_error: 0.4129\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3174 - mean_absolute_error: 0.3928 - val_loss: 0.4191 - val_mean_absolute_error: 0.4163\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3115 - mean_absolute_error: 0.3905 - val_loss: 0.3383 - val_mean_absolute_error: 0.4130\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3116 - mean_absolute_error: 0.3881 - val_loss: 0.4250 - val_mean_absolute_error: 0.4043\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3096 - mean_absolute_error: 0.3849 - val_loss: 0.3313 - val_mean_absolute_error: 0.4036\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3000 - mean_absolute_error: 0.3820 - val_loss: 0.3561 - val_mean_absolute_error: 0.4117\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3016 - mean_absolute_error: 0.3810 - val_loss: 0.3854 - val_mean_absolute_error: 0.3978\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2965 - mean_absolute_error: 0.3789 - val_loss: 0.3397 - val_mean_absolute_error: 0.3932\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2928 - mean_absolute_error: 0.3759 - val_loss: 0.3227 - val_mean_absolute_error: 0.3952\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2914 - mean_absolute_error: 0.3749 - val_loss: 0.3645 - val_mean_absolute_error: 0.3952\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2952 - mean_absolute_error: 0.3748 - val_loss: 0.3173 - val_mean_absolute_error: 0.3899\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2897 - mean_absolute_error: 0.3722 - val_loss: 0.3391 - val_mean_absolute_error: 0.4029\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2918 - mean_absolute_error: 0.3731 - val_loss: 0.3549 - val_mean_absolute_error: 0.3922\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2904 - mean_absolute_error: 0.3729 - val_loss: 0.3239 - val_mean_absolute_error: 0.4025\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2844 - mean_absolute_error: 0.3689 - val_loss: 0.3310 - val_mean_absolute_error: 0.3869\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2834 - mean_absolute_error: 0.3683 - val_loss: 0.3118 - val_mean_absolute_error: 0.3821\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2812 - mean_absolute_error: 0.3670 - val_loss: 0.3152 - val_mean_absolute_error: 0.3852\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2822 - mean_absolute_error: 0.3676 - val_loss: 0.3710 - val_mean_absolute_error: 0.3907\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2889 - mean_absolute_error: 0.3678 - val_loss: 0.3297 - val_mean_absolute_error: 0.3924\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2819 - mean_absolute_error: 0.3669 - val_loss: 0.3564 - val_mean_absolute_error: 0.3839\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2807 - mean_absolute_error: 0.3668 - val_loss: 0.3150 - val_mean_absolute_error: 0.3849\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2774 - mean_absolute_error: 0.3640 - val_loss: 0.3329 - val_mean_absolute_error: 0.3896\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2797 - mean_absolute_error: 0.3648 - val_loss: 0.3255 - val_mean_absolute_error: 0.3830\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2781 - mean_absolute_error: 0.3647 - val_loss: 0.3170 - val_mean_absolute_error: 0.3837\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2755 - mean_absolute_error: 0.3630 - val_loss: 0.3580 - val_mean_absolute_error: 0.3818\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2845 - mean_absolute_error: 0.3640 - val_loss: 0.3271 - val_mean_absolute_error: 0.3859\n",
      "--- Model Training Finished ---\n",
      "--- Evaluating Model on Test Set ---\n",
      "Final Test Set MSE (Mean Squared Error): 0.2978\n",
      "Final Test Set MAE (Mean Absolute Error): 0.3722\n"
     ]
    }
   ],
   "source": [
    "# California Housing Dataset pre-processing and neural network model\n",
    "\n",
    "# First, split into 80% (train+validation) and 20% (test)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Next, split the 80% into 80% (training) and 20% (validation)\n",
    "# This results in 64% train, 16% validation, 20% test\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
<<<<<<< HEAD
    "# Wrap in scikit-learn compatible estimator\n",
    "sklearn_model = KerasClassifier(model=create_model, epochs=10, batch_size=256, verbose=0)\n",
    "sklearn_model.fit(X_train_adult, y_train_adult)  # Train the model\n",
    "\"\"\"\n"
=======
    "print(f\"Total data points: {len(X)}\")\n",
    "print(f\"Training data points: {len(X_train)}\")\n",
    "print(f\"Validation data points: {len(X_valid)}\")\n",
    "print(f\"Test data points: {len(X_test)}\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test data\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data successfully scaled.\")\n",
    "print(f\"Original mean (first feature): {X_train[:, 0].mean():.4f}\")\n",
    "print(f\"Scaled mean (first feature): {X_train_scaled[:, 0].mean():.4f}\")\n",
    "\n",
    "# Get the number of features from our training data\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Input layer: Specify input shape in the first layer\n",
    "    layers.Dense(32, activation=\"relu\", input_shape=[n_features]),\n",
    "    \n",
    "    # Hidden layer\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    \n",
    "    # Output layer for regression\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",  # This is the MSE\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"mean_absolute_error\"] # We can also track MAE\n",
    ")\n",
    "\n",
    "print(\"Model compiled with 'mean_squared_error' as the loss function.\")\n",
    "\n",
    "print(\"--- Starting Model Training ---\")\n",
    "\n",
    "# Early stopping stops training when validation loss stops improving\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,         # Wait 10 epochs for improvement\n",
    "    restore_best_weights=True  # Go back to the best version\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1 # Show progress\n",
    ")\n",
    "\n",
    "print(\"--- Model Training Finished ---\")\n",
    "\n",
    "print(\"--- Evaluating Model on Test Set ---\")\n",
    "\n",
    "# model.evaluate() returns [loss, metric1, metric2, ...]\n",
    "# Since our loss is 'mean_squared_error', the first value is the MSE.\n",
    "results = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "final_mse = results[0]\n",
    "final_mae = results[1]\n",
    "\n",
    "print(f\"Final Test Set MSE (Mean Squared Error): {final_mse:.4f}\")\n",
    "print(f\"Final Test Set MAE (Mean Absolute Error): {final_mae:.4f}\")\n",
    "\n",
    "# The MAE (in $100,000s) is often easier to understand\n",
    "# e.g., an MAE of 0.5 means the average error is $50,000."
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b7af9",
   "metadata": {},
   "source": [
    "## 1. Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots (7 marks) \n",
    "### a. Use PDP to examine the average effect of at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3fe303b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This KerasWrapper instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
<<<<<<< HEAD
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m feature_indices \u001b[38;5;241m=\u001b[39m [numeric_feature_names\u001b[38;5;241m.\u001b[39mindex(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_for_pdp]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Plot PDP\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_feature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_plot\\partial_dependence.py:707\u001b[0m, in \u001b[0;36mPartialDependenceDisplay.from_estimator\u001b[1;34m(cls, estimator, X, features, sample_weight, categorical_features, feature_names, target, response_method, n_cols, grid_resolution, percentiles, method, n_jobs, verbose, line_kw, ice_lines_kw, pd_line_kw, contour_kw, ax, kind, centered, subsample, random_state)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    702\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen a floating-point, subsample=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe (0, 1) range.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         )\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# compute predictions and/or averaged predictions\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m pd_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_dependence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# For multioutput regression, we can only check the validity of target\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# now that we have the predictions.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# Also note: as multiclass-multioutput classifiers are not supported,\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# multiclass and multioutput scenario are mutually exclusive. So there is\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# no risk of overwriting target_idx here.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m pd_result \u001b[38;5;241m=\u001b[39m pd_results[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# checking the first result is enough\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_partial_dependence.py:534\u001b[0m, in \u001b[0;36mpartial_dependence\u001b[1;34m(estimator, X, features, sample_weight, categorical_features, feature_names, response_method, percentiles, grid_resolution, method, kind)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    322\u001b[0m     {\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m     kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m ):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Partial dependence of ``features``.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    Partial dependence of a feature (or a set of features) corresponds to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m    (array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_classifier(estimator) \u001b[38;5;129;01mor\u001b[39;00m is_regressor(estimator)):\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a fitted regressor or classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This KerasWrapper instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
=======
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[40], line 35\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- plot PDPs ---\u001b[39;00m\n",
      "\u001b[0;32m     34\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;32m---> 35\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_wrapper\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val_adult\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43medu_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhours_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# tuple -> 2D PDP (interaction)\u001b[39;49;00m\n",
      "\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\n",
      "\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial Dependence: Education × Hours-per-week\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_plot\\partial_dependence.py:707\u001b[0m, in \u001b[0;36mPartialDependenceDisplay.from_estimator\u001b[1;34m(cls, estimator, X, features, sample_weight, categorical_features, feature_names, target, response_method, n_cols, grid_resolution, percentiles, method, n_jobs, verbose, line_kw, ice_lines_kw, pd_line_kw, contour_kw, ax, kind, centered, subsample, random_state)\u001b[0m\n",
      "\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    702\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen a floating-point, subsample=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe (0, 1) range.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    704\u001b[0m         )\n",
      "\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# compute predictions and/or averaged predictions\u001b[39;00m\n",
      "\u001b[1;32m--> 707\u001b[0m pd_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_dependence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_resolution\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# For multioutput regression, we can only check the validity of target\u001b[39;00m\n",
      "\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# now that we have the predictions.\u001b[39;00m\n",
      "\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# Also note: as multiclass-multioutput classifiers are not supported,\u001b[39;00m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# multiclass and multioutput scenario are mutually exclusive. So there is\u001b[39;00m\n",
      "\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# no risk of overwriting target_idx here.\u001b[39;00m\n",
      "\u001b[0;32m    729\u001b[0m pd_result \u001b[38;5;241m=\u001b[39m pd_results[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# checking the first result is enough\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[0;32m     76\u001b[0m )\n",
      "\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m    214\u001b[0m         )\n",
      "\u001b[0;32m    215\u001b[0m     ):\n",
      "\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[0;32m    226\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_partial_dependence.py:537\u001b[0m, in \u001b[0;36mpartial_dependence\u001b[1;34m(estimator, X, features, sample_weight, categorical_features, feature_names, response_method, percentiles, grid_resolution, method, kind)\u001b[0m\n",
      "\u001b[0;32m    534\u001b[0m check_is_fitted(estimator)\n",
      "\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_classifier(estimator) \u001b[38;5;129;01mor\u001b[39;00m is_regressor(estimator)):\n",
      "\u001b[1;32m--> 537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a fitted regressor or classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(estimator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulticlass-multioutput estimators are not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: 'estimator' must be a fitted regressor or classifier."
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric features for PDP\n",
    "X_train_numeric = X_train_adult[:, -len(num_cols):]  # last columns are scaled numeric\n",
    "numeric_feature_names = list(num_cols)  # ['age', 'fnlwgt', 'education-num', ...]\n",
    "\n",
    "# Wrap your trained model\n",
    "class KerasWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = self.model.predict(X, verbose=0).flatten()\n",
    "        return np.vstack([1 - probs, probs]).T\n",
    "\n",
    "wrapped_model = KerasWrapper(model)\n",
    "wrapped_model.fit(X_train_numeric)\n",
    "\n",
    "# Pick features: 'age' and 'hours-per-week'\n",
    "features_for_pdp = ['age', 'hours-per-week']\n",
    "feature_indices = [numeric_feature_names.index(f) for f in features_for_pdp]\n",
    "\n",
    "# Plot PDP\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    wrapped_model,\n",
    "    X_train_numeric,\n",
    "    features=feature_indices,\n",
    "    feature_names=numeric_feature_names,\n",
    "    grid_resolution=20\n",
=======
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# --- Keras → sklearn wrapper ---\n",
    "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
    "    _estimator_type = \"regressor\"  # tell sklearn what this is\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        # mark as fitted\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        preds = self.model.predict(X, verbose=0)\n",
    "        return preds.flatten()\n",
    "\n",
    "# wrap model\n",
    "keras_wrapper = KerasRegressorWrapper(model)\n",
    "keras_wrapper.fit()  # mark as fitted\n",
    "\n",
    "# --- PDP setup ---\n",
    "feature_names = list(ct.get_feature_names_out())\n",
    "edu_idx = feature_names.index('scale__education-num')\n",
    "hours_idx = feature_names.index('scale__hours-per-week')\n",
    "\n",
    "# --- plot PDPs ---\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    keras_wrapper,\n",
    "    X_val_adult,\n",
    "    features=[(edu_idx, hours_idx)],  # tuple -> 2D PDP (interaction)\n",
    "    feature_names=feature_names,\n",
    "    grid_resolution=40,\n",
    "    ax=ax\n",
>>>>>>> 1991a9fdd155191a5b4b184b685cb1e6dd7a3bed
    ")\n",
    "plt.suptitle(\"Partial Dependence: Education × Hours-per-week\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#California Housing Data Set NN + PDP + ICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b39bef",
   "metadata": {},
   "source": [
    "### b. Use ICE plots to explore individual predictions for at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bdca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b6405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fcb7c1",
   "metadata": {},
   "source": [
    "### c. Explain what insights PDP and ICE give about the model’s behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f80c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5948c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e357bb",
   "metadata": {},
   "source": [
    "## 2. Permutation Feature Importance (PFI) (7 marks) \n",
    "### a. Use PFI to identify the most important features in the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ac11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a323045b",
   "metadata": {},
   "source": [
    "### b. Explain what the term “important” means when using the PFI method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054de319",
   "metadata": {},
   "source": [
    "## 3. Accumulated Local Effects (ALE) (9 marks) \n",
    "### a. Implement ALE plots to investigate the local effects of feature changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82633524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0aa2f07",
   "metadata": {},
   "source": [
    "### b. Compare ALE with PDP and discuss any differences in the interpretability of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387257b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1eb403",
   "metadata": {},
   "source": [
    "## 4. Global Surrogates (7 marks) \n",
    "### a. Build an interpretable model to approximate the predictions of the feed-forward neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265eeb5b",
   "metadata": {},
   "source": [
    "### b. Analyse the surrogate model's effectiveness and discuss when such approximations are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
