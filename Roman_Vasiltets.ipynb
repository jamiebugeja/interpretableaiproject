{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416211f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ff856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "train_adult = pd.read_csv(\"DataSets/census/adult.data\", header=None, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True)\n",
    "test_adult = pd.read_csv(\"DataSets/census/adult.test\", header=0, names=columns, sep=\",\", na_values=\" ?\", skipinitialspace=True, comment='|')\n",
    "test_adult['income'] = test_adult['income'].str.replace('.', '', regex=False)\n",
    "\n",
    "data_adult = pd.concat([train_adult, test_adult], ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e81b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (20640, 8)\n",
      "Target (y) shape: (20640,)\n",
      "\n",
      "Feature names:\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(\"\\nFeature names:\")\n",
    "print(housing.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16896f5e",
   "metadata": {},
   "source": [
    "# Part 1: Feature-Level Interpretability (30 marks)  \n",
    "You will use the California Housing and the Adult Census Income datasets in this part. You \n",
    "should train one feed-forward neural network for each dataset and apply the following \n",
    "interpretability techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777ef54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7881 - loss: 0.4447 - val_accuracy: 0.8539 - val_loss: 0.3168\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.3196 - val_accuracy: 0.8552 - val_loss: 0.3121\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3113 - val_accuracy: 0.8576 - val_loss: 0.3095\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8589 - loss: 0.3074 - val_accuracy: 0.8575 - val_loss: 0.3077\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.3073 - val_accuracy: 0.8584 - val_loss: 0.3081\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8606 - loss: 0.3047 - val_accuracy: 0.8594 - val_loss: 0.3061\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.3059 - val_accuracy: 0.8584 - val_loss: 0.3073\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3010 - val_accuracy: 0.8598 - val_loss: 0.3073\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 0.3014 - val_accuracy: 0.8600 - val_loss: 0.3066\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8619 - loss: 0.3019 - val_accuracy: 0.8604 - val_loss: 0.3069\n",
      "Validation Accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nfrom scikeras.wrappers import KerasClassifier\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\\nfrom sklearn.inspection import PartialDependenceDisplay\\nimport matplotlib.pyplot as plt\\n\\n# Wrap the Keras model\\ndef create_model():\\n    model = Sequential([\\n        Dense(128, activation='relu', input_dim=input_dim),\\n        Dropout(0.3),\\n        Dense(64, activation='relu'),\\n        Dropout(0.3),\\n        Dense(1, activation='sigmoid')\\n    ])\\n    model.compile(optimizer=Adam(learning_rate=0.001),\\n                  loss='binary_crossentropy', metrics=['accuracy'])\\n    return model\\n\\n# Wrap in scikit-learn compatible estimator\\nsklearn_model = KerasClassifier(model=create_model, epochs=10, batch_size=256, verbose=0)\\nsklearn_model.fit(X_train_adult, y_train_adult)  # Train the model\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adult Census Income Dataset pre-processing and neural network model\n",
    "\n",
    "X_adult = data_adult.drop(\"income\", axis=1)\n",
    "y_adult = (data_adult[\"income\"] == \">50K\").astype(int)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = X_adult.select_dtypes(include=['object']).columns\n",
    "num_cols = X_adult.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Encode categorical & scale numeric\n",
    "ct = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('scale', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "X_processed_adult = ct.fit_transform(X_adult)\n",
    "X_train_adult, X_val_adult, y_train_adult, y_val_adult = train_test_split(X_processed_adult, y_adult, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim = X_train_adult.shape[1]\n",
    "\n",
    "# The feed-forward neural network model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=input_dim),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_adult, y_train_adult,\n",
    "    validation_data=(X_val_adult, y_val_adult),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaulate the model\n",
    "loss, acc = model.evaluate(X_val_adult, y_val_adult, verbose=0)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "841f30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 20640\n",
      "Training data points: 13209\n",
      "Validation data points: 3303\n",
      "Test data points: 4128\n",
      "Data successfully scaled\n",
      "Original mean (first feature): 3.8689\n",
      "Scaled mean (first feature): -0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\UoM\\Year 3\\ARI3205 Interpretable AI for DL Models\\interpretableaiproject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> (12.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,201\u001b[0m (12.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> (12.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,201\u001b[0m (12.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled with MSE as the loss function and Dropout Layers and a custom Adam.\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.0097 - mean_absolute_error: 0.7006 - val_loss: 0.4684 - val_mean_absolute_error: 0.4839\n",
      "Epoch 2/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5490 - mean_absolute_error: 0.5315 - val_loss: 0.4474 - val_mean_absolute_error: 0.4681\n",
      "Epoch 3/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4735 - mean_absolute_error: 0.4941 - val_loss: 0.4393 - val_mean_absolute_error: 0.4642\n",
      "Epoch 4/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4564 - mean_absolute_error: 0.4805 - val_loss: 0.4288 - val_mean_absolute_error: 0.4556\n",
      "Epoch 5/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4306 - mean_absolute_error: 0.4712 - val_loss: 0.4103 - val_mean_absolute_error: 0.4483\n",
      "Epoch 6/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4096 - mean_absolute_error: 0.4584 - val_loss: 0.3859 - val_mean_absolute_error: 0.4446\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4012 - mean_absolute_error: 0.4520 - val_loss: 0.4043 - val_mean_absolute_error: 0.4416\n",
      "Epoch 8/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3946 - mean_absolute_error: 0.4464 - val_loss: 0.4067 - val_mean_absolute_error: 0.4442\n",
      "Epoch 9/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3883 - mean_absolute_error: 0.4390 - val_loss: 0.4553 - val_mean_absolute_error: 0.4435\n",
      "Epoch 10/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3864 - mean_absolute_error: 0.4327 - val_loss: 0.4324 - val_mean_absolute_error: 0.4367\n",
      "Epoch 11/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3643 - mean_absolute_error: 0.4283 - val_loss: 0.3662 - val_mean_absolute_error: 0.4198\n",
      "Epoch 12/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3605 - mean_absolute_error: 0.4239 - val_loss: 0.3721 - val_mean_absolute_error: 0.4201\n",
      "Epoch 13/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3543 - mean_absolute_error: 0.4201 - val_loss: 0.3800 - val_mean_absolute_error: 0.4236\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3535 - mean_absolute_error: 0.4179 - val_loss: 0.3636 - val_mean_absolute_error: 0.4139\n",
      "Epoch 15/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3433 - mean_absolute_error: 0.4149 - val_loss: 0.3412 - val_mean_absolute_error: 0.4067\n",
      "Epoch 16/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3504 - mean_absolute_error: 0.4154 - val_loss: 0.3346 - val_mean_absolute_error: 0.4014\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3375 - mean_absolute_error: 0.4109 - val_loss: 0.3527 - val_mean_absolute_error: 0.4118\n",
      "Epoch 18/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3371 - mean_absolute_error: 0.4076 - val_loss: 0.3519 - val_mean_absolute_error: 0.4077\n",
      "Epoch 19/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3394 - mean_absolute_error: 0.4071 - val_loss: 0.3654 - val_mean_absolute_error: 0.4162\n",
      "Epoch 20/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3303 - mean_absolute_error: 0.4032 - val_loss: 0.3248 - val_mean_absolute_error: 0.3988\n",
      "Epoch 21/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3280 - mean_absolute_error: 0.3994 - val_loss: 0.3321 - val_mean_absolute_error: 0.3991\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3266 - mean_absolute_error: 0.4014 - val_loss: 0.3204 - val_mean_absolute_error: 0.3932\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3275 - mean_absolute_error: 0.3987 - val_loss: 0.3411 - val_mean_absolute_error: 0.4085\n",
      "Epoch 24/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3207 - mean_absolute_error: 0.3967 - val_loss: 0.3791 - val_mean_absolute_error: 0.4163\n",
      "Epoch 25/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3185 - mean_absolute_error: 0.3938 - val_loss: 0.3141 - val_mean_absolute_error: 0.3843\n",
      "Epoch 26/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3136 - mean_absolute_error: 0.3922 - val_loss: 0.3282 - val_mean_absolute_error: 0.3901\n",
      "Epoch 27/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3181 - mean_absolute_error: 0.3924 - val_loss: 0.3688 - val_mean_absolute_error: 0.4054\n",
      "Epoch 28/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3131 - mean_absolute_error: 0.3902 - val_loss: 0.3690 - val_mean_absolute_error: 0.4145\n",
      "Epoch 29/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3144 - mean_absolute_error: 0.3903 - val_loss: 0.3418 - val_mean_absolute_error: 0.3917\n",
      "Epoch 30/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3071 - mean_absolute_error: 0.3858 - val_loss: 0.3045 - val_mean_absolute_error: 0.3817\n",
      "Epoch 31/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3122 - mean_absolute_error: 0.3866 - val_loss: 0.3274 - val_mean_absolute_error: 0.3839\n",
      "Epoch 32/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3064 - mean_absolute_error: 0.3846 - val_loss: 0.3359 - val_mean_absolute_error: 0.3864\n",
      "Epoch 33/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3052 - mean_absolute_error: 0.3857 - val_loss: 0.3130 - val_mean_absolute_error: 0.3827\n",
      "Epoch 34/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3068 - mean_absolute_error: 0.3833 - val_loss: 0.3613 - val_mean_absolute_error: 0.3862\n",
      "Epoch 35/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3092 - mean_absolute_error: 0.3843 - val_loss: 0.3073 - val_mean_absolute_error: 0.3814\n",
      "Epoch 36/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3027 - mean_absolute_error: 0.3806 - val_loss: 0.3240 - val_mean_absolute_error: 0.3917\n",
      "Epoch 37/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3013 - mean_absolute_error: 0.3809 - val_loss: 0.3263 - val_mean_absolute_error: 0.3942\n",
      "Epoch 38/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2977 - mean_absolute_error: 0.3783 - val_loss: 0.3443 - val_mean_absolute_error: 0.3975\n",
      "Epoch 39/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2973 - mean_absolute_error: 0.3786 - val_loss: 0.3365 - val_mean_absolute_error: 0.3916\n",
      "Epoch 40/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2937 - mean_absolute_error: 0.3764 - val_loss: 0.3546 - val_mean_absolute_error: 0.4010\n",
      "Epoch 41/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2971 - mean_absolute_error: 0.3788 - val_loss: 0.3199 - val_mean_absolute_error: 0.3863\n",
      "Epoch 42/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2948 - mean_absolute_error: 0.3759 - val_loss: 0.3162 - val_mean_absolute_error: 0.3886\n",
      "Epoch 43/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2922 - mean_absolute_error: 0.3750 - val_loss: 0.3187 - val_mean_absolute_error: 0.3827\n",
      "Epoch 44/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2914 - mean_absolute_error: 0.3736 - val_loss: 0.3531 - val_mean_absolute_error: 0.3986\n",
      "Epoch 45/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2911 - mean_absolute_error: 0.3722 - val_loss: 0.3028 - val_mean_absolute_error: 0.3809\n",
      "Epoch 46/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2886 - mean_absolute_error: 0.3731 - val_loss: 0.2980 - val_mean_absolute_error: 0.3729\n",
      "Epoch 47/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2899 - mean_absolute_error: 0.3709 - val_loss: 0.3212 - val_mean_absolute_error: 0.3909\n",
      "Epoch 48/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2927 - mean_absolute_error: 0.3733 - val_loss: 0.3012 - val_mean_absolute_error: 0.3775\n",
      "Epoch 49/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2904 - mean_absolute_error: 0.3734 - val_loss: 0.3086 - val_mean_absolute_error: 0.3780\n",
      "Epoch 50/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2860 - mean_absolute_error: 0.3694 - val_loss: 0.2929 - val_mean_absolute_error: 0.3690\n",
      "Epoch 51/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2849 - mean_absolute_error: 0.3680 - val_loss: 0.3034 - val_mean_absolute_error: 0.3755\n",
      "Epoch 52/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2899 - mean_absolute_error: 0.3716 - val_loss: 0.2955 - val_mean_absolute_error: 0.3690\n",
      "Epoch 53/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2876 - mean_absolute_error: 0.3703 - val_loss: 0.3131 - val_mean_absolute_error: 0.3857\n",
      "Epoch 54/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2848 - mean_absolute_error: 0.3710 - val_loss: 0.2931 - val_mean_absolute_error: 0.3746\n",
      "Epoch 55/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2865 - mean_absolute_error: 0.3708 - val_loss: 0.2907 - val_mean_absolute_error: 0.3681\n",
      "Epoch 56/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2838 - mean_absolute_error: 0.3685 - val_loss: 0.2956 - val_mean_absolute_error: 0.3747\n",
      "Epoch 57/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2810 - mean_absolute_error: 0.3666 - val_loss: 0.2976 - val_mean_absolute_error: 0.3770\n",
      "Epoch 58/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2808 - mean_absolute_error: 0.3667 - val_loss: 0.2949 - val_mean_absolute_error: 0.3760\n",
      "Epoch 59/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2865 - mean_absolute_error: 0.3679 - val_loss: 0.2934 - val_mean_absolute_error: 0.3808\n",
      "Epoch 60/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2850 - mean_absolute_error: 0.3670 - val_loss: 0.3113 - val_mean_absolute_error: 0.3832\n",
      "Epoch 61/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2836 - mean_absolute_error: 0.3668 - val_loss: 0.3028 - val_mean_absolute_error: 0.3779\n",
      "Epoch 62/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2823 - mean_absolute_error: 0.3668 - val_loss: 0.3020 - val_mean_absolute_error: 0.3794\n",
      "Epoch 63/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2823 - mean_absolute_error: 0.3666 - val_loss: 0.3093 - val_mean_absolute_error: 0.3800\n",
      "Epoch 64/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2806 - mean_absolute_error: 0.3663 - val_loss: 0.2942 - val_mean_absolute_error: 0.3730\n",
      "Epoch 65/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2796 - mean_absolute_error: 0.3655 - val_loss: 0.2888 - val_mean_absolute_error: 0.3713\n",
      "Epoch 66/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2804 - mean_absolute_error: 0.3653 - val_loss: 0.3123 - val_mean_absolute_error: 0.3813\n",
      "Epoch 67/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2778 - mean_absolute_error: 0.3637 - val_loss: 0.2981 - val_mean_absolute_error: 0.3771\n",
      "Epoch 68/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2748 - mean_absolute_error: 0.3638 - val_loss: 0.3024 - val_mean_absolute_error: 0.3745\n",
      "Epoch 69/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2792 - mean_absolute_error: 0.3644 - val_loss: 0.3042 - val_mean_absolute_error: 0.3818\n",
      "Epoch 70/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2770 - mean_absolute_error: 0.3627 - val_loss: 0.3077 - val_mean_absolute_error: 0.3785\n",
      "Epoch 71/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2742 - mean_absolute_error: 0.3635 - val_loss: 0.2857 - val_mean_absolute_error: 0.3700\n",
      "Epoch 72/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2773 - mean_absolute_error: 0.3639 - val_loss: 0.2959 - val_mean_absolute_error: 0.3708\n",
      "Epoch 73/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2811 - mean_absolute_error: 0.3660 - val_loss: 0.2947 - val_mean_absolute_error: 0.3712\n",
      "Epoch 74/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2787 - mean_absolute_error: 0.3647 - val_loss: 0.2910 - val_mean_absolute_error: 0.3697\n",
      "Epoch 75/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2765 - mean_absolute_error: 0.3640 - val_loss: 0.2943 - val_mean_absolute_error: 0.3665\n",
      "Epoch 76/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2783 - mean_absolute_error: 0.3625 - val_loss: 0.3059 - val_mean_absolute_error: 0.3748\n",
      "Epoch 77/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2763 - mean_absolute_error: 0.3646 - val_loss: 0.2873 - val_mean_absolute_error: 0.3676\n",
      "Epoch 78/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2755 - mean_absolute_error: 0.3631 - val_loss: 0.2939 - val_mean_absolute_error: 0.3734\n",
      "Epoch 79/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2782 - mean_absolute_error: 0.3632 - val_loss: 0.2844 - val_mean_absolute_error: 0.3704\n",
      "Epoch 80/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2751 - mean_absolute_error: 0.3609 - val_loss: 0.2946 - val_mean_absolute_error: 0.3813\n",
      "Epoch 81/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2750 - mean_absolute_error: 0.3608 - val_loss: 0.2868 - val_mean_absolute_error: 0.3638\n",
      "Epoch 82/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2754 - mean_absolute_error: 0.3617 - val_loss: 0.2931 - val_mean_absolute_error: 0.3690\n",
      "Epoch 83/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2743 - mean_absolute_error: 0.3603 - val_loss: 0.2875 - val_mean_absolute_error: 0.3757\n",
      "Epoch 84/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2699 - mean_absolute_error: 0.3616 - val_loss: 0.2981 - val_mean_absolute_error: 0.3671\n",
      "Epoch 85/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2776 - mean_absolute_error: 0.3612 - val_loss: 0.3042 - val_mean_absolute_error: 0.3860\n",
      "Epoch 86/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2729 - mean_absolute_error: 0.3607 - val_loss: 0.2881 - val_mean_absolute_error: 0.3698\n",
      "Epoch 87/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2700 - mean_absolute_error: 0.3586 - val_loss: 0.2999 - val_mean_absolute_error: 0.3715\n",
      "Epoch 88/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2702 - mean_absolute_error: 0.3578 - val_loss: 0.2809 - val_mean_absolute_error: 0.3546\n",
      "Epoch 89/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2706 - mean_absolute_error: 0.3588 - val_loss: 0.2834 - val_mean_absolute_error: 0.3667\n",
      "Epoch 90/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2720 - mean_absolute_error: 0.3589 - val_loss: 0.2893 - val_mean_absolute_error: 0.3705\n",
      "Epoch 91/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2745 - mean_absolute_error: 0.3613 - val_loss: 0.2826 - val_mean_absolute_error: 0.3672\n",
      "Epoch 92/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2697 - mean_absolute_error: 0.3582 - val_loss: 0.2950 - val_mean_absolute_error: 0.3663\n",
      "Epoch 93/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2739 - mean_absolute_error: 0.3609 - val_loss: 0.2818 - val_mean_absolute_error: 0.3627\n",
      "Epoch 94/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2730 - mean_absolute_error: 0.3587 - val_loss: 0.2860 - val_mean_absolute_error: 0.3683\n",
      "Epoch 95/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2687 - mean_absolute_error: 0.3585 - val_loss: 0.2807 - val_mean_absolute_error: 0.3531\n",
      "Epoch 96/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2714 - mean_absolute_error: 0.3570 - val_loss: 0.3470 - val_mean_absolute_error: 0.4059\n",
      "Epoch 97/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2724 - mean_absolute_error: 0.3603 - val_loss: 0.2955 - val_mean_absolute_error: 0.3719\n",
      "Epoch 98/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2750 - mean_absolute_error: 0.3597 - val_loss: 0.3116 - val_mean_absolute_error: 0.3776\n",
      "Epoch 99/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2710 - mean_absolute_error: 0.3582 - val_loss: 0.2931 - val_mean_absolute_error: 0.3729\n",
      "Epoch 100/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2667 - mean_absolute_error: 0.3563 - val_loss: 0.2870 - val_mean_absolute_error: 0.3771\n",
      "--- Model Training Finished ---\n",
      "--- Evaluating Model on Test Set ---\n",
      "Final Test Set MSE (Mean Squared Error): 0.2761\n",
      "Final Test Set MAE (Mean Absolute Error): 0.3480\n"
     ]
    }
   ],
   "source": [
    "# California Housing Dataset pre-processing and neural network model\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total data points: {len(X)}\")\n",
    "print(f\"Training data points: {len(X_train)}\")\n",
    "print(f\"Validation data points: {len(X_valid)}\")\n",
    "print(f\"Test data points: {len(X_test)}\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data successfully scaled\")\n",
    "print(f\"Original mean (first feature): {X_train[:, 0].mean():.4f}\")\n",
    "print(f\"Scaled mean (first feature): {X_train_scaled[:, 0].mean():.4f}\")\n",
    "\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    layers.Dense(64, activation=\"relu\", input_shape=[n_features]),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    \n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"mean_absolute_error\"]\n",
    ")\n",
    "\n",
    "print(\"Model compiled with MSE as the loss function and Dropout Layers and a custom Adam.\")\n",
    "\n",
    "print(\"--- Starting Model Training ---\")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"--- Model Training Finished ---\")\n",
    "\n",
    "print(\"--- Evaluating Model on Test Set ---\")\n",
    "\n",
    "results = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "final_mse = results[0]\n",
    "final_mae = results[1]\n",
    "\n",
    "print(f\"Final Test Set MSE (Mean Squared Error): {final_mse:.4f}\")\n",
    "print(f\"Final Test Set MAE (Mean Absolute Error): {final_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b7af9",
   "metadata": {},
   "source": [
    "## 1. Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots (7 marks) \n",
    "### a. Use PDP to examine the average effect of at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3fe303b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This KerasWrapper instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m feature_indices \u001b[38;5;241m=\u001b[39m [numeric_feature_names\u001b[38;5;241m.\u001b[39mindex(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_for_pdp]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Plot PDP\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_feature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_plot\\partial_dependence.py:707\u001b[0m, in \u001b[0;36mPartialDependenceDisplay.from_estimator\u001b[1;34m(cls, estimator, X, features, sample_weight, categorical_features, feature_names, target, response_method, n_cols, grid_resolution, percentiles, method, n_jobs, verbose, line_kw, ice_lines_kw, pd_line_kw, contour_kw, ax, kind, centered, subsample, random_state)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    702\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen a floating-point, subsample=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe (0, 1) range.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         )\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# compute predictions and/or averaged predictions\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m pd_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_dependence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# For multioutput regression, we can only check the validity of target\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# now that we have the predictions.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# Also note: as multiclass-multioutput classifiers are not supported,\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# multiclass and multioutput scenario are mutually exclusive. So there is\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# no risk of overwriting target_idx here.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m pd_result \u001b[38;5;241m=\u001b[39m pd_results[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# checking the first result is enough\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\inspection\\_partial_dependence.py:534\u001b[0m, in \u001b[0;36mpartial_dependence\u001b[1;34m(estimator, X, features, sample_weight, categorical_features, feature_names, response_method, percentiles, grid_resolution, method, kind)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    322\u001b[0m     {\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m     kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m ):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Partial dependence of ``features``.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    Partial dependence of a feature (or a set of features) corresponds to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m    (array([[-4.52...,  4.52...]]), [array([ 0.,  1.])])\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 534\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_classifier(estimator) \u001b[38;5;129;01mor\u001b[39;00m is_regressor(estimator)):\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a fitted regressor or classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jamie\\OneDrive\\Desktop\\Interpretable AI Project\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This KerasWrapper instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric features for PDP\n",
    "X_train_numeric = X_train_adult[:, -len(num_cols):]  # last columns are scaled numeric\n",
    "numeric_feature_names = list(num_cols)  # ['age', 'fnlwgt', 'education-num', ...]\n",
    "\n",
    "# Wrap your trained model\n",
    "class KerasWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = self.model.predict(X, verbose=0).flatten()\n",
    "        return np.vstack([1 - probs, probs]).T\n",
    "\n",
    "wrapped_model = KerasWrapper(model)\n",
    "wrapped_model.fit(X_train_numeric)\n",
    "\n",
    "# Pick features: 'age' and 'hours-per-week'\n",
    "features_for_pdp = ['age', 'hours-per-week']\n",
    "feature_indices = [numeric_feature_names.index(f) for f in features_for_pdp]\n",
    "\n",
    "# Plot PDP\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    wrapped_model,\n",
    "    X_train_numeric,\n",
    "    features=feature_indices,\n",
    "    feature_names=numeric_feature_names,\n",
    "    grid_resolution=20\n",
    ")\n",
    "plt.suptitle(\"Partial Dependence: Education × Hours-per-week\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#California Housing Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b39bef",
   "metadata": {},
   "source": [
    "### b. Use ICE plots to explore individual predictions for at least two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bdca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b6405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fcb7c1",
   "metadata": {},
   "source": [
    "### c. Explain what insights PDP and ICE give about the model’s behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f80c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5948c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e357bb",
   "metadata": {},
   "source": [
    "## 2. Permutation Feature Importance (PFI) (7 marks) \n",
    "### a. Use PFI to identify the most important features in the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ac11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a323045b",
   "metadata": {},
   "source": [
    "### b. Explain what the term “important” means when using the PFI method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054de319",
   "metadata": {},
   "source": [
    "## 3. Accumulated Local Effects (ALE) (9 marks) \n",
    "### a. Implement ALE plots to investigate the local effects of feature changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82633524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0aa2f07",
   "metadata": {},
   "source": [
    "### b. Compare ALE with PDP and discuss any differences in the interpretability of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387257b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad1eb403",
   "metadata": {},
   "source": [
    "## 4. Global Surrogates (7 marks) \n",
    "### a. Build an interpretable model to approximate the predictions of the feed-forward neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265eeb5b",
   "metadata": {},
   "source": [
    "### b. Analyse the surrogate model's effectiveness and discuss when such approximations are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd145a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
